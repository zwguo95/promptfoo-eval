description: "Evaluation for Social Safety Net Chatbot (letter-only accuracy + rationale & citations)"

providers: file://providers.yaml

prompts:
  - id: file://../prompts/mcq-letter-only.txt
    label: mcq-letter-only
  - id: file://../prompts/mcq-rationale-citations.txt
    label: mcq-rationale-citations

defaultTest:
  options:
    temperature: 0
    timeout: 360000
  evaluateOptions:
    seed: 42
    maxConcurrency: 4

tests:
  - dataset: file://../datasets/tests.csv
    prompt: file://../prompts/mcq-letter-only.txt
    tags: ["test", "accuracy"]
    assert:
      - type: equals
        value: "{{answer_key}}"
        trim: true
        ignoreCase: true
      - type: not-contains
        value: "I can't help with that"
      - type: latency
        max: 8000

  - dataset: file://../datasets/tests.csv
    prompt: file://../prompts/mcq-rationale-citations.txt
    tags: ["test", "rationale"]
    assert:
      - type: not-contains
        value: "I can't help with that"
      - type: latency
        max: 12000
      - type: rubric
        value: file://../rubrics/rationale_quality.md
        provider: openai:gpt-4o-mini
        weight: 0.7
      - type: rubric
        value: file://../rubrics/groundedness.md
        provider: openai:gpt-4o-mini
        weight: 0.3

scoring:
  - file: file://scoring.yaml

view:
  showLatency: true
  showCosts: true
  groupBy: ["provider", "tags"]

outputPath: "results/${ISO_TIMESTAMP}"

providersOptions:
  http:nava-dst:
    headers:
      Content-Type: application/json