# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

prompts:
  - file://prompts/mcq-rationale.txt

providers:
  - file://configs/nava-provider.yaml

tests:
  - path: file://tests/dataset.csv
    assert:
      # 2) Rationale QUALITY (judge only the rationale line)
      - type: llm-rubric
        provider: openai:o4-mini
        value: file://rubrics/rationale_quality.txt
        threshold: 0.7
        metric: rationale_quality
        options:
          transform: |
            const l = String(output || '').split(/\r?\n/);
            return (l[1] || '').replace(/^Rationale:\s*/i, '').trim();

      # 3) GROUNDEDNESS (judge only the citations line)
      - type: llm-rubric
        provider: openai:o4-mini
        value: file://rubrics/groundedness.txt
        threshold: 0.7
        metric: groundedness
        options:
          transform: |
            const l = String(output || '').split(/\r?\n/);
            return (l[2] || '').replace(/^Citations:\s*/i, '').trim();

defaultTest:
  vars:
    uniqueSessionId: file://scripts/generateUniqueId.js
  assert: [] # suppress default __expected check

outputPath: "results/latest.csv"